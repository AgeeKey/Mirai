#!/usr/bin/env python3
"""
üß† MIRAI V3 SUPERAGENT - PHASE 7: MEMORY & LEARNING
–ü–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –∏ –æ–±—É—á–µ–Ω–∏—è (150 —à–∞–≥–æ–≤)

–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
- Memory System (STM, WM, LTM, Episodic, Semantic, Procedural)
- Experience Recording
- Pattern Recognition
- Learning Engine
- Knowledge Management
- Advanced Reasoning
- Continuous Improvement

–ê–≤—Ç–æ—Ä: MIRAI Team
–í–µ—Ä—Å–∏—è: 3.0
–î–∞—Ç–∞: 2025
"""

import logging
import sqlite3
import json
import pickle
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Set
from dataclasses import dataclass, field, asdict
from collections import deque, defaultdict
from concurrent.futures import ThreadPoolExecutor
import hashlib
import numpy as np
from enum import Enum
import threading
import time
from abc import ABC, abstractmethod

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ OpenAI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ============================================================================
# –†–ê–ó–î–ï–õ 1: –ë–ê–ó–û–í–´–ï –°–¢–†–£–ö–¢–£–†–´ –ò –¢–ò–ü–´ (–®–∞–≥–∏ 1-5)
# ============================================================================

# –®–∞–≥ 1-2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# –®–∞–≥ 3: –¢–∏–ø—ã –ø–∞–º—è—Ç–∏
class MemoryType(Enum):
    """–¢–∏–ø—ã –ø–∞–º—è—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º–µ"""
    SHORT_TERM = "short_term"      # –ö—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å
    WORKING = "working"             # –†–∞–±–æ—á–∞—è –ø–∞–º—è—Ç—å
    LONG_TERM = "long_term"         # –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å
    EPISODIC = "episodic"           # –≠–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å
    SEMANTIC = "semantic"           # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å
    PROCEDURAL = "procedural"       # –ü—Ä–æ—Ü–µ–¥—É—Ä–Ω–∞—è –ø–∞–º—è—Ç—å


# –®–∞–≥ 4: –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏
@dataclass
class MemoryItem:
    """–ë–∞–∑–æ–≤–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –ø–∞–º—è—Ç–∏"""
    id: str
    content: Dict[str, Any]
    memory_type: MemoryType
    timestamp: datetime = field(default_factory=datetime.now)
    importance: float = 0.5
    access_count: int = 0
    last_accessed: Optional[datetime] = None
    embedding: Optional[np.ndarray] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        d = asdict(self)
        d['timestamp'] = self.timestamp.isoformat()
        d['last_accessed'] = self.last_accessed.isoformat() if self.last_accessed else None
        d['memory_type'] = self.memory_type.value
        d['embedding'] = self.embedding.tolist() if self.embedding is not None else None
        return d
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'MemoryItem':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        data = data.copy()
        data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        if data.get('last_accessed'):
            data['last_accessed'] = datetime.fromisoformat(data['last_accessed'])
        data['memory_type'] = MemoryType(data['memory_type'])
        if data.get('embedding'):
            data['embedding'] = np.array(data['embedding'])
        return cls(**data)


@dataclass
class EventActionResult:
    """
    Event-Action-Result Triple
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ –æ–ø—ã—Ç–∞
    """
    event: Dict[str, Any]
    action: Dict[str, Any]
    result: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)
    success: bool = False
    confidence: float = 0.0
    
    def to_dict(self) -> Dict:
        d = asdict(self)
        d["timestamp"] = self.timestamp.isoformat()
        return d


# ============================================================================
# –†–ê–ó–î–ï–õ 2: –ö–û–ú–ü–û–ù–ï–ù–¢–´ –ü–ê–ú–Ø–¢–ò (–®–∞–≥–∏ 6-15)
# ============================================================================

# –®–∞–≥ 6: Short-Term Memory
class ShortTermMemory:
    """
    –ö—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å
    - –•—Ä–∞–Ω–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–µ–π—Å—Ç–≤–∏–π
    - –ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–±—ã–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    """
    
    def __init__(self, capacity: int = 20):
        """
        Args:
            capacity: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        """
        self.capacity = capacity
        self.buffer: deque = deque(maxlen=capacity)
        self.created_at = datetime.now()
        
        logger.info(f"‚úÖ Short-Term Memory —Å–æ–∑–¥–∞–Ω–∞ (capacity={capacity})")
    
    def add(self, item: MemoryItem):
        """–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å"""
        self.buffer.append(item)
        logger.debug(f"üìù –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ STM: {item.id}")
    
    def get_recent(self, n: int = 5) -> List[MemoryItem]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
        return list(self.buffer)[-n:] if len(self.buffer) >= n else list(self.buffer)
    
    def get_all(self) -> List[MemoryItem]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã"""
        return list(self.buffer)
    
    def clear(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å"""
        self.buffer.clear()
        logger.info("üßπ Short-Term Memory –æ—á–∏—â–µ–Ω–∞")
    
    def __len__(self):
        return len(self.buffer)


# –®–∞–≥ 7: Working Memory
class WorkingMemory:
    """
    –†–∞–±–æ—á–∞—è –ø–∞–º—è—Ç—å
    - –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏
    - –ê–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    - –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    """
    
    def __init__(self):
        self.current_task: Optional[Dict] = None
        self.context: Dict[str, Any] = {}
        self.active_items: List[MemoryItem] = []
        self.created_at = datetime.now()
        
        logger.info("‚úÖ Working Memory —Å–æ–∑–¥–∞–Ω–∞")
    
    def set_task(self, task: Dict):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â—É—é –∑–∞–¥–∞—á—É"""
        self.current_task = task
        logger.info(f"üìã –ó–∞–¥–∞—á–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {task.get('name', 'Unknown')}")
    
    def update_context(self, key: str, value: Any):
        """–û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        self.context[key] = value
    
    def add_item(self, item: MemoryItem):
        """–î–æ–±–∞–≤–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç"""
        self.active_items.append(item)
    
    def clear(self):
        """–û—á–∏—Å—Ç–∏—Ç—å —Ä–∞–±–æ—á—É—é –ø–∞–º—è—Ç—å"""
        self.current_task = None
        self.context = {}
        self.active_items = []
        logger.info("üßπ Working Memory –æ—á–∏—â–µ–Ω–∞")
    
    def get_context(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        return {
            'task': self.current_task,
            'context': self.context,
            'active_items_count': len(self.active_items)
        }


# –®–∞–≥ 8: Long-Term Memory
class LongTermMemory:
    """
    –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å
    - –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    - SQLite –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    - –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–æ–∏—Å–∫
    """
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)
        
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row
        self._create_tables()
        
        logger.info(f"‚úÖ Long-Term Memory –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {db_path}")
    
    def _create_tables(self):
        """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã –ë–î"""
        cursor = self.conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ –ø–∞–º—è—Ç–∏
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS memories (
                id TEXT PRIMARY KEY,
                content TEXT NOT NULL,
                memory_type TEXT NOT NULL,
                timestamp TIMESTAMP NOT NULL,
                importance REAL DEFAULT 0.5,
                access_count INTEGER DEFAULT 0,
                last_accessed TIMESTAMP,
                metadata TEXT,
                embedding BLOB
            )
        """)
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON memories(timestamp)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_type ON memories(memory_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_importance ON memories(importance)")
        
        self.conn.commit()
    
    def store(self, item: MemoryItem):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å"""
        cursor = self.conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO memories 
            (id, content, memory_type, timestamp, importance, access_count, last_accessed, metadata, embedding)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            item.id,
            json.dumps(item.content, ensure_ascii=False),
            item.memory_type.value,
            item.timestamp.isoformat(),
            item.importance,
            item.access_count,
            item.last_accessed.isoformat() if item.last_accessed else None,
            json.dumps(item.metadata, ensure_ascii=False),
            pickle.dumps(item.embedding) if item.embedding is not None else None
        ))
        
        self.conn.commit()
        logger.debug(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ LTM: {item.id}")
    
    def retrieve(self, item_id: str) -> Optional[MemoryItem]:
        """–ü–æ–ª—É—á–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –ø–æ ID"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT * FROM memories WHERE id = ?", (item_id,))
        row = cursor.fetchone()
        
        if row:
            return self._row_to_memory_item(row)
        return None
    
    def _row_to_memory_item(self, row) -> MemoryItem:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏ –ë–î –≤ MemoryItem"""
        return MemoryItem(
            id=row['id'],
            content=json.loads(row['content']),
            memory_type=MemoryType(row['memory_type']),
            timestamp=datetime.fromisoformat(row['timestamp']),
            importance=row['importance'],
            access_count=row['access_count'],
            last_accessed=datetime.fromisoformat(row['last_accessed']) if row['last_accessed'] else None,
            metadata=json.loads(row['metadata']) if row['metadata'] else {},
            embedding=pickle.loads(row['embedding']) if row['embedding'] else None
        )
    
    def query_by_type(self, memory_type: MemoryType, limit: int = 10) -> List[MemoryItem]:
        """–ó–∞–ø—Ä–æ—Å –ø–æ —Ç–∏–ø—É –ø–∞–º—è—Ç–∏"""
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT * FROM memories WHERE memory_type = ? ORDER BY timestamp DESC LIMIT ?",
            (memory_type.value, limit)
        )
        return [self._row_to_memory_item(row) for row in cursor.fetchall()]
    
    def count_memories(self) -> int:
        """–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM memories")
        return cursor.fetchone()[0]


# –®–∞–≥ 9: Episodic Memory
class EpisodicMemory:
    """
    –≠–ø–∏–∑–æ–¥–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å
    - –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
    - "–ß—Ç–æ, –∫–æ–≥–¥–∞, –≥–¥–µ, –∫–∞–∫, –ø–æ—á–µ–º—É"
    - –õ–∏—á–Ω—ã–π –æ–ø—ã—Ç –∞–≥–µ–Ω—Ç–∞
    """
    
    def __init__(self, ltm: LongTermMemory):
        self.ltm = ltm
        self.episodes: List[Dict] = []
        
        logger.info("‚úÖ Episodic Memory —Å–æ–∑–¥–∞–Ω–∞")
    
    def record_episode(self, 
                      event: str, 
                      context: Dict, 
                      outcome: Dict,
                      timestamp: Optional[datetime] = None) -> str:
        """
        –ó–∞–ø–∏—Å–∞—Ç—å —ç–ø–∏–∑–æ–¥
        
        Args:
            event: –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–±—ã—Ç–∏—è
            outcome: –†–µ–∑—É–ª—å—Ç–∞—Ç
            timestamp: –í—Ä–µ–º—è —Å–æ–±—ã—Ç–∏—è
            
        Returns:
            ID —ç–ø–∏–∑–æ–¥–∞
        """
        if timestamp is None:
            timestamp = datetime.now()
        
        episode_id = f"episode_{timestamp.strftime('%Y%m%d_%H%M%S')}_{hashlib.md5(event.encode()).hexdigest()[:8]}"
        
        episode = {
            'event': event,
            'context': context,
            'outcome': outcome,
            'timestamp': timestamp.isoformat()
        }
        
        memory_item = MemoryItem(
            id=episode_id,
            content=episode,
            memory_type=MemoryType.EPISODIC,
            timestamp=timestamp,
            importance=self._calculate_importance(outcome)
        )
        
        self.ltm.store(memory_item)
        logger.info(f"üìñ –≠–ø–∏–∑–æ–¥ –∑–∞–ø–∏—Å–∞–Ω: {event[:50]}...")
        
        return episode_id
    
    def _calculate_importance(self, outcome: Dict) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å —ç–ø–∏–∑–æ–¥–∞"""
        if outcome.get('success'):
            return 0.7
        elif outcome.get('error'):
            return 0.8  # –û—à–∏–±–∫–∏ –≤–∞–∂–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        return 0.5


# –®–∞–≥ 10: Semantic Memory
class SemanticMemory:
    """
    –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å
    - –û–±—â–∏–µ –∑–Ω–∞–Ω–∏—è
    - –§–∞–∫—Ç—ã
    - –ö–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
    """
    
    def __init__(self, ltm: LongTermMemory):
        self.ltm = ltm
        self.knowledge_base: Dict[str, Any] = {}
        
        logger.info("‚úÖ Semantic Memory —Å–æ–∑–¥–∞–Ω–∞")
    
    def store_fact(self, subject: str, predicate: str, object_: str, confidence: float = 1.0):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–∫—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ (—Å—É–±—ä–µ–∫—Ç, –ø—Ä–µ–¥–∏–∫–∞—Ç, –æ–±—ä–µ–∫—Ç)
        
        Args:
            subject: –°—É–±—ä–µ–∫—Ç
            predicate: –ü—Ä–µ–¥–∏–∫–∞—Ç (–æ—Ç–Ω–æ—à–µ–Ω–∏–µ)
            object_: –û–±—ä–µ–∫—Ç
            confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ñ–∞–∫—Ç–µ
        """
        fact_id = f"fact_{hashlib.md5(f'{subject}_{predicate}_{object_}'.encode()).hexdigest()[:8]}"
        
        fact = {
            'subject': subject,
            'predicate': predicate,
            'object': object_,
            'confidence': confidence
        }
        
        memory_item = MemoryItem(
            id=fact_id,
            content=fact,
            memory_type=MemoryType.SEMANTIC,
            importance=confidence
        )
        
        self.ltm.store(memory_item)
        self.knowledge_base[fact_id] = fact
        logger.info(f"üß† –§–∞–∫—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {subject} {predicate} {object_}")
    
    def query_facts(self, subject: Optional[str] = None) -> List[Dict]:
        """–ó–∞–ø—Ä–æ—Å —Ñ–∞–∫—Ç–æ–≤ –ø–æ —Å—É–±—ä–µ–∫—Ç—É"""
        results = []
        for fact_id, fact in self.knowledge_base.items():
            if subject is None or fact.get('subject') == subject:
                results.append(fact)
        return results


# –®–∞–≥ 11: Procedural Memory
class ProceduralMemory:
    """
    –ü—Ä–æ—Ü–µ–¥—É—Ä–Ω–∞—è –ø–∞–º—è—Ç—å
    - –ù–∞–≤—ã–∫–∏
    - –ü—Ä–æ—Ü–µ–¥—É—Ä—ã
    - "–ö–∞–∫ –¥–µ–ª–∞—Ç—å –≤–µ—â–∏"
    """
    
    def __init__(self, ltm: LongTermMemory):
        self.ltm = ltm
        self.procedures: Dict[str, Dict] = {}
        
        logger.info("‚úÖ Procedural Memory —Å–æ–∑–¥–∞–Ω–∞")
    
    def store_procedure(self, 
                       name: str, 
                       steps: List[Dict],
                       success_rate: float = 0.0):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ—Ü–µ–¥—É—Ä—É
        
        Args:
            name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã
            steps: –®–∞–≥–∏ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã
            success_rate: –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
        """
        proc_id = f"proc_{hashlib.md5(name.encode()).hexdigest()[:8]}"
        
        procedure = {
            'name': name,
            'steps': steps,
            'success_rate': success_rate,
            'execution_count': 0
        }
        
        memory_item = MemoryItem(
            id=proc_id,
            content=procedure,
            memory_type=MemoryType.PROCEDURAL,
            importance=success_rate
        )
        
        self.ltm.store(memory_item)
        self.procedures[name] = procedure
        
        logger.info(f"‚öôÔ∏è –ü—Ä–æ—Ü–µ–¥—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {name}")
    
    def get_procedure(self, name: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ—Ü–µ–¥—É—Ä—É –ø–æ –∏–º–µ–Ω–∏"""
        return self.procedures.get(name)
    
    def update_success_rate(self, name: str, success: bool):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É—Å–ø–µ—Ö–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã"""
        if name in self.procedures:
            proc = self.procedures[name]
            proc['execution_count'] += 1
            alpha = 0.1
            proc['success_rate'] = (1 - alpha) * proc['success_rate'] + alpha * (1.0 if success else 0.0)
            logger.debug(f"üìä –û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {name} -> {proc['success_rate']:.2f}")


# ============================================================================
# –†–ê–ó–î–ï–õ 3: –°–ò–°–¢–ï–ú–´ –û–ë–†–ê–ë–û–¢–ö–ò (–®–∞–≥–∏ 12-20)
# ============================================================================

# –®–∞–≥ 12: Memory Encoder
class MemoryEncoder:
    """
    –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ –ø–∞–º—è—Ç–∏
    - –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ OpenAI text-embedding-3-large (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    - 3072-–º–µ—Ä–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if self.api_key and OPENAI_AVAILABLE:
            openai.api_key = self.api_key
        
        self.model = "text-embedding-3-large"
        self.cache: Dict[str, np.ndarray] = {}
        self.use_openai = bool(self.api_key and OPENAI_AVAILABLE)
        
        logger.info(f"‚úÖ Memory Encoder —Å–æ–∑–¥–∞–Ω (OpenAI: {self.use_openai})")
    
    def encode(self, text: str) -> np.ndarray:
        """
        –ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cache_key = hashlib.md5(text.encode()).hexdigest()
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        try:
            if self.use_openai:
                response = openai.embeddings.create(
                    model=self.model,
                    input=text
                )
                embedding = np.array(response.data[0].embedding)
            else:
                # Fallback: –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                np.random.seed(int(cache_key[:8], 16))
                embedding = np.random.rand(3072)
            
            self.cache[cache_key] = embedding
            logger.debug(f"üî¢ –¢–µ–∫—Å—Ç –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: {text[:50]}...")
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            # Fallback
            np.random.seed(int(cache_key[:8], 16))
            return np.random.rand(3072)
    
    def encode_memory_item(self, item: MemoryItem) -> MemoryItem:
        """–î–æ–±–∞–≤–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –∫ —ç–ª–µ–º–µ–Ω—Ç—É –ø–∞–º—è—Ç–∏"""
        text = json.dumps(item.content, ensure_ascii=False)
        item.embedding = self.encode(text)
        return item


# –®–∞–≥ 13: Memory Retriever
class MemoryRetriever:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
    - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
    - –ü–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É
    - –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    
    def __init__(self, ltm: LongTermMemory, encoder: MemoryEncoder):
        self.ltm = ltm
        self.encoder = encoder
        
        logger.info("‚úÖ Memory Retriever —Å–æ–∑–¥–∞–Ω")
    
    def search_by_similarity(self, query: str, top_k: int = 5) -> List[Tuple[MemoryItem, float]]:
        """
        –ü–æ–∏—Å–∫ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É
        
        Args:
            query: –ó–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ (MemoryItem, similarity_score)
        """
        query_embedding = self.encoder.encode(query)
        
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        cursor = self.ltm.conn.cursor()
        cursor.execute("SELECT * FROM memories WHERE embedding IS NOT NULL")
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            item = self.ltm._row_to_memory_item(row)
            if item.embedding is not None:
                similarity = self._cosine_similarity(query_embedding, item.embedding)
                results.append((item, similarity))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É
        results.sort(key=lambda x: x[1], reverse=True)
        
        return results[:top_k]
    
    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return float(dot_product / (norm1 * norm2))
    
    def retrieve_recent(self, n: int = 10, memory_type: Optional[MemoryType] = None) -> List[MemoryItem]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
        cursor = self.ltm.conn.cursor()
        
        if memory_type:
            cursor.execute(
                "SELECT * FROM memories WHERE memory_type = ? ORDER BY timestamp DESC LIMIT ?",
                (memory_type.value, n)
            )
        else:
            cursor.execute(
                "SELECT * FROM memories ORDER BY timestamp DESC LIMIT ?",
                (n,)
            )
        
        return [self.ltm._row_to_memory_item(row) for row in cursor.fetchall()]


# –®–∞–≥ 14: Memory Consolidation
class MemoryConsolidation:
    """
    –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
    - –ü–µ—Ä–µ–Ω–æ—Å –∏–∑ –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é
    - –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
    - –£–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
    """
    
    def __init__(self, stm: ShortTermMemory, ltm: LongTermMemory, encoder: MemoryEncoder):
        self.stm = stm
        self.ltm = ltm
        self.encoder = encoder
        self._running = False
        
        logger.info("‚úÖ Memory Consolidation —Å–æ–∑–¥–∞–Ω–∞")
    
    def consolidate(self, threshold: float = 0.6) -> int:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é
        
        Args:
            threshold: –ü–æ—Ä–æ–≥ –≤–∞–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –≤ LTM
            
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        """
        items_to_consolidate = []
        
        for item in self.stm.get_all():
            if item.importance >= threshold:
                # –î–æ–±–∞–≤–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                if item.embedding is None:
                    item = self.encoder.encode_memory_item(item)
                
                items_to_consolidate.append(item)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ LTM
        for item in items_to_consolidate:
            self.ltm.store(item)
        
        logger.info(f"üí´ –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(items_to_consolidate)}")
        
        return len(items_to_consolidate)
    
    def start_auto_consolidation(self, interval: int = 3600):
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é
        
        Args:
            interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self._running = True
        
        def consolidate_worker():
            while self._running:
                try:
                    self.consolidate()
                    time.sleep(interval)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏: {e}")
                    time.sleep(60)
        
        thread = threading.Thread(target=consolidate_worker, daemon=True)
        thread.start()
        logger.info(f"üîÑ –ê–≤—Ç–æ–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞ (interval={interval}s)")
    
    def stop_auto_consolidation(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–≤—Ç–æ–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é"""
        self._running = False
        logger.info("‚èπÔ∏è –ê–≤—Ç–æ–∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")


# ============================================================================
# –†–ê–ó–î–ï–õ 4: –†–ê–°–®–ò–†–ï–ù–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò (–®–∞–≥–∏ 16-30)
# ============================================================================

# –®–∞–≥ 16: Vector Database
class VectorDB:
    """
    –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    - –•—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    - –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É
    """
    
    def __init__(self):
        self.vectors: List[np.ndarray] = []
        self.ids: List[str] = []
        self.metadata: List[Dict] = []
        
        logger.info("‚úÖ Vector DB —Å–æ–∑–¥–∞–Ω–∞")
    
    def add(self, id_: str, vector: np.ndarray, metadata: Dict = None):
        """–î–æ–±–∞–≤–∏—Ç—å –≤–µ–∫—Ç–æ—Ä"""
        self.vectors.append(vector)
        self.ids.append(id_)
        self.metadata.append(metadata or {})
    
    def search(self, query_vector: np.ndarray, top_k: int = 5) -> List[Tuple[str, float, Dict]]:
        """–ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"""
        if not self.vectors:
            return []
        
        similarities = []
        for i, vec in enumerate(self.vectors):
            norm_query = np.linalg.norm(query_vector)
            norm_vec = np.linalg.norm(vec)
            
            if norm_query > 0 and norm_vec > 0:
                sim = np.dot(query_vector, vec) / (norm_query * norm_vec)
                similarities.append((self.ids[i], float(sim), self.metadata[i]))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_k]
    
    def __len__(self):
        return len(self.vectors)


# –®–∞–≥ 17: Memory Indexer
class MemoryIndexer:
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
    - –ò–Ω–¥–µ–∫—Å—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏, —Ç–∏–ø—É, –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
    - –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
    """
    
    def __init__(self, ltm: LongTermMemory):
        self.ltm = ltm
        self.time_index: Dict[str, List[str]] = defaultdict(list)
        self.type_index: Dict[str, List[str]] = defaultdict(list)
        self.tag_index: Dict[str, List[str]] = defaultdict(list)
        
        self._rebuild_indexes()
        logger.info("‚úÖ Memory Indexer —Å–æ–∑–¥–∞–Ω")
    
    def _rebuild_indexes(self):
        """–ü–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—å –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã"""
        cursor = self.ltm.conn.cursor()
        cursor.execute("SELECT id, memory_type, timestamp, metadata FROM memories")
        
        for row in cursor.fetchall():
            date_key = row['timestamp'][:10]
            self.time_index[date_key].append(row['id'])
            self.type_index[row['memory_type']].append(row['id'])
            
            if row['metadata']:
                metadata = json.loads(row['metadata'])
                for tag in metadata.get('tags', []):
                    self.tag_index[tag].append(row['id'])
    
    def find_by_date(self, date: str) -> List[str]:
        """–ù–∞–π—Ç–∏ –ø–æ –¥–∞—Ç–µ (YYYY-MM-DD)"""
        return self.time_index.get(date, [])
    
    def find_by_type(self, memory_type: MemoryType) -> List[str]:
        """–ù–∞–π—Ç–∏ –ø–æ —Ç–∏–ø—É –ø–∞–º—è—Ç–∏"""
        return self.type_index.get(memory_type.value, [])
    
    def find_by_tag(self, tag: str) -> List[str]:
        """–ù–∞–π—Ç–∏ –ø–æ —Ç–µ–≥—É"""
        return self.tag_index.get(tag, [])


# –®–∞–≥ 18-19: Attention & Decay
class AttentionMechanism:
    """–ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
    
    def __init__(self):
        self.weights: Dict[str, float] = {}
        logger.info("‚úÖ Attention Mechanism —Å–æ–∑–¥–∞–Ω")
    
    def calculate_attention_weights(self, 
                                   query: str,
                                   memories: List[MemoryItem],
                                   encoder: MemoryEncoder) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è"""
        query_embedding = encoder.encode(query)
        weights = {}
        
        for memory in memories:
            if memory.embedding is not None:
                # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
                norm_q = np.linalg.norm(query_embedding)
                norm_m = np.linalg.norm(memory.embedding)
                
                if norm_q > 0 and norm_m > 0:
                    similarity = np.dot(query_embedding, memory.embedding) / (norm_q * norm_m)
                else:
                    similarity = 0.0
                
                # –£—á–µ—Å—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –∏ —Å–≤–µ–∂–µ—Å—Ç—å
                time_decay = self._time_decay(memory.timestamp)
                weight = float(similarity * memory.importance * time_decay)
                
                weights[memory.id] = weight
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        total = sum(weights.values())
        if total > 0:
            weights = {k: v / total for k, v in weights.items()}
        
        return weights
    
    def _time_decay(self, timestamp: datetime, half_life_days: float = 7.0) -> float:
        """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —Å–ø–∞–¥ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º"""
        age_days = (datetime.now() - timestamp).days
        return 2 ** (-age_days / half_life_days)


class MemoryDecay:
    """–ó–∞–±—ã–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
    
    def __init__(self, ltm: LongTermMemory, half_life_days: float = 30.0):
        self.ltm = ltm
        self.half_life_days = half_life_days
        
        logger.info(f"‚úÖ Memory Decay —Å–æ–∑–¥–∞–Ω (half_life={half_life_days} days)")
    
    def apply_decay(self) -> int:
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∑–∞–±—ã–≤–∞–Ω–∏–µ"""
        cursor = self.ltm.conn.cursor()
        cursor.execute("SELECT id, timestamp, importance FROM memories")
        
        updated = 0
        for row in cursor.fetchall():
            old_importance = row['importance']
            timestamp = datetime.fromisoformat(row['timestamp'])
            
            age_days = (datetime.now() - timestamp).days
            decay_factor = 2 ** (-age_days / self.half_life_days)
            new_importance = old_importance * decay_factor
            
            if abs(new_importance - old_importance) > 0.01:
                cursor.execute(
                    "UPDATE memories SET importance = ? WHERE id = ?",
                    (new_importance, row['id'])
                )
                updated += 1
        
        self.ltm.conn.commit()
        logger.info(f"‚è≥ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –∑–∞–±—ã–≤–∞–Ω–∏–µ –∫ {updated} –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è–º")
        
        return updated


# –®–∞–≥ 20: Memory Reinforcement
class MemoryReinforcement:
    """–£–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π"""
    
    def __init__(self, ltm: LongTermMemory):
        self.ltm = ltm
        logger.info("‚úÖ Memory Reinforcement —Å–æ–∑–¥–∞–Ω")
    
    def reinforce(self, memory_id: str, strength: float = 0.1):
        """–£–∫—Ä–µ–ø–∏—Ç—å –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ"""
        cursor = self.ltm.conn.cursor()
        cursor.execute(
            "SELECT importance, access_count FROM memories WHERE id = ?",
            (memory_id,)
        )
        row = cursor.fetchone()
        
        if row:
            new_importance = min(1.0, row['importance'] + strength)
            new_access_count = row['access_count'] + 1
            
            cursor.execute("""
                UPDATE memories 
                SET importance = ?, 
                    access_count = ?,
                    last_accessed = ?
                WHERE id = ?
            """, (new_importance, new_access_count, datetime.now().isoformat(), memory_id))
            
            self.ltm.conn.commit()
            logger.debug(f"üí™ –£–∫—Ä–µ–ø–ª–µ–Ω–æ: {memory_id}")


# ============================================================================
# –†–ê–ó–î–ï–õ 5: –ó–ê–ü–ò–°–¨ –û–ü–´–¢–ê –ò –ü–ê–¢–¢–ï–†–ù–´ (–®–∞–≥–∏ 30-60)
# ============================================================================

# –®–∞–≥ 27: Experience Recorder
class ExperienceRecorder:
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤–µ—Å—å –æ–ø—ã—Ç –∞–≥–µ–Ω—Ç–∞
    - –°–æ–±—ã—Ç–∏—è, –¥–µ–π—Å—Ç–≤–∏—è, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    - –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    """
    
    def __init__(self, memory_system: 'MemorySystem'):
        self.memory_system = memory_system
        self.experiences: List[EventActionResult] = []
        
        logger.info("‚úÖ Experience Recorder —Å–æ–∑–¥–∞–Ω")
    
    def record_experience(self,
                         event: Dict[str, Any],
                         action: Dict[str, Any],
                         result: Dict[str, Any],
                         context: Optional[Dict] = None) -> str:
        """–ó–∞–ø–∏—Å–∞—Ç—å –æ–ø—ã—Ç"""
        ear = EventActionResult(
            event=event,
            action=action,
            result=result,
            success=result.get('success', False),
            confidence=result.get('confidence', 0.5)
        )
        
        self.experiences.append(ear)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ episodic memory
        episode_id = self.memory_system.episodic_memory.record_episode(
            event=json.dumps(event, ensure_ascii=False),
            context=context or {},
            outcome=result
        )
        
        # –î–æ–±–∞–≤–∏—Ç—å –≤ short-term memory
        memory_item = MemoryItem(
            id=episode_id,
            content=ear.to_dict(),
            memory_type=MemoryType.EPISODIC,
            importance=self._evaluate_importance(ear)
        )
        
        self.memory_system.short_term_memory.add(memory_item)
        
        logger.info(f"üìù –û–ø—ã—Ç –∑–∞–ø–∏—Å–∞–Ω: {episode_id}")
        
        return episode_id
    
    def _evaluate_importance(self, ear: EventActionResult) -> float:
        """–û—Ü–µ–Ω–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –æ–ø—ã—Ç–∞"""
        importance = 0.5
        
        if ear.success:
            importance = 0.4
        else:
            importance = 0.8
        
        importance *= ear.confidence
        
        return min(1.0, importance)


# –®–∞–≥ 51: Pattern Detector
class PatternDetector:
    """
    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    - –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –¥–µ–π—Å—Ç–≤–∏—è
    - –£—Å–ø–µ—à–Ω—ã–µ/–Ω–µ—É—Å–ø–µ—à–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, memory_system: 'MemorySystem'):
        self.memory_system = memory_system
        self.detected_patterns: List[Dict] = []
        
        logger.info("‚úÖ Pattern Detector —Å–æ–∑–¥–∞–Ω")
    
    def detect_action_patterns(self, min_occurrences: int = 3) -> List[Dict]:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–µ–π—Å—Ç–≤–∏–π"""
        recent_memories = self.memory_system.retriever.retrieve_recent(n=100)
        
        action_groups = defaultdict(list)
        for memory in recent_memories:
            if memory.memory_type == MemoryType.EPISODIC:
                action_content = memory.content.get('action', {})
                if isinstance(action_content, dict):
                    action_type = action_content.get('type')
                    if action_type:
                        action_groups[action_type].append(memory)
        
        patterns = []
        for action_type, memories in action_groups.items():
            if len(memories) >= min_occurrences:
                pattern = {
                    'type': 'action_repetition',
                    'action_type': action_type,
                    'occurrences': len(memories),
                    'success_rate': self._calculate_success_rate(memories),
                    'avg_confidence': self._calculate_avg_confidence(memories)
                }
                patterns.append(pattern)
        
        self.detected_patterns.extend(patterns)
        logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(patterns)}")
        
        return patterns
    
    def _calculate_success_rate(self, memories: List[MemoryItem]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞"""
        if not memories:
            return 0.0
        
        successes = sum(1 for m in memories 
                       if isinstance(m.content.get('result'), dict) and 
                       m.content.get('result', {}).get('success', False))
        return successes / len(memories)
    
    def _calculate_avg_confidence(self, memories: List[MemoryItem]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"""
        if not memories:
            return 0.0
        
        confidences = [m.content.get('result', {}).get('confidence', 0.5) 
                      for m in memories 
                      if isinstance(m.content.get('result'), dict)]
        return sum(confidences) / len(confidences) if confidences else 0.0


# ============================================================================
# –†–ê–ó–î–ï–õ 6: –û–ë–£–ß–ï–ù–ò–ï (–®–∞–≥–∏ 61-90)
# ============================================================================

# –®–∞–≥ 76: Learning Engine
class LearningEngine:
    """
    –î–≤–∏–∂–æ–∫ –æ–±—É—á–µ–Ω–∏—è
    - –û–±—É—á–µ–Ω–∏–µ –∏–∑ —É—Å–ø–µ—Ö–æ–≤ –∏ –Ω–µ—É–¥–∞—á
    - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π
    """
    
    def __init__(self, memory_system: 'MemorySystem'):
        self.memory_system = memory_system
        self.learned_rules: List[Dict] = []
        
        logger.info("‚úÖ Learning Engine —Å–æ–∑–¥–∞–Ω")
    
    def learn_from_experience(self, experience_id: str):
        """–û–±—É—á–∏—Ç—å—Å—è –∏–∑ –æ–ø—ã—Ç–∞"""
        memory = self.memory_system.long_term_memory.retrieve(experience_id)
        
        if not memory:
            logger.warning(f"‚ö†Ô∏è –û–ø—ã—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {experience_id}")
            return
        
        content = memory.content
        result = content.get('result', {})
        success = result.get('success', False) if isinstance(result, dict) else False
        
        if success:
            self._learn_from_success(memory)
        else:
            self._learn_from_failure(memory)
    
    def _learn_from_success(self, memory: MemoryItem):
        """–û–±—É—á–µ–Ω–∏–µ –∏–∑ —É—Å–ø–µ—Ö–∞"""
        action = memory.content.get('action', {})
        context = memory.content.get('context', {})
        
        rule = {
            'type': 'success_pattern',
            'action_type': action.get('type') if isinstance(action, dict) else 'unknown',
            'context': context,
            'confidence': 0.7,
            'learned_at': datetime.now().isoformat()
        }
        
        self.learned_rules.append(rule)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ semantic memory
        action_type = action.get('type') if isinstance(action, dict) else 'unknown_action'
        self.memory_system.semantic_memory.store_fact(
            subject=action_type,
            predicate='works_in_context',
            object_=json.dumps(context, ensure_ascii=False),
            confidence=0.7
        )
        
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∏–∑ —É—Å–ø–µ—Ö–∞: {action_type}")
    
    def _learn_from_failure(self, memory: MemoryItem):
        """–û–±—É—á–µ–Ω–∏–µ –∏–∑ –Ω–µ—É–¥–∞—á–∏"""
        action = memory.content.get('action', {})
        result = memory.content.get('result', {})
        error = result.get('error') if isinstance(result, dict) else 'unknown_error'
        
        rule = {
            'type': 'failure_pattern',
            'action_type': action.get('type') if isinstance(action, dict) else 'unknown',
            'error': error,
            'confidence': 0.6,
            'learned_at': datetime.now().isoformat()
        }
        
        self.learned_rules.append(rule)
        
        action_type = action.get('type') if isinstance(action, dict) else 'unknown_action'
        logger.info(f"‚ùå –û–±—É—á–µ–Ω–∏–µ –∏–∑ –Ω–µ—É–¥–∞—á–∏: {action_type} -> {error}")


# ============================================================================
# –†–ê–ó–î–ï–õ 7: –£–ü–†–ê–í–õ–ï–ù–ò–ï –ó–ù–ê–ù–ò–Ø–ú–ò (–®–∞–≥–∏ 91-120)
# ============================================================================

# –®–∞–≥ 101: Knowledge Graph
class KnowledgeGraph:
    """
    –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
    - –£–∑–ª—ã: –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, —Å—É—â–Ω–æ—Å—Ç–∏
    - –†—ë–±—Ä–∞: –æ—Ç–Ω–æ—à–µ–Ω–∏—è
    """
    
    def __init__(self):
        self.nodes: Dict[str, Dict] = {}
        self.edges: List[Tuple[str, str, str]] = []
        
        logger.info("‚úÖ Knowledge Graph —Å–æ–∑–¥–∞–Ω")
    
    def add_node(self, node_id: str, node_type: str, properties: Dict = None):
        """–î–æ–±–∞–≤–∏—Ç—å —É–∑–µ–ª"""
        self.nodes[node_id] = {
            'type': node_type,
            'properties': properties or {},
            'created_at': datetime.now().isoformat()
        }
    
    def add_edge(self, from_id: str, relation: str, to_id: str):
        """–î–æ–±–∞–≤–∏—Ç—å —Ä–µ–±—Ä–æ"""
        self.edges.append((from_id, relation, to_id))
    
    def query(self, subject: Optional[str] = None, 
             relation: Optional[str] = None,
             object_: Optional[str] = None) -> List[Tuple]:
        """–ó–∞–ø—Ä–æ—Å –∫ –≥—Ä–∞—Ñ—É"""
        results = []
        
        for edge in self.edges:
            from_id, rel, to_id = edge
            
            if subject and from_id != subject:
                continue
            if relation and rel != relation:
                continue
            if object_ and to_id != object_:
                continue
            
            results.append(edge)
        
        return results
    
    def get_neighbors(self, node_id: str) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å–µ–¥–µ–π —É–∑–ª–∞"""
        neighbors = []
        for from_id, rel, to_id in self.edges:
            if from_id == node_id:
                neighbors.append(to_id)
        return neighbors


# ============================================================================
# –†–ê–ó–î–ï–õ 8: –ì–õ–ê–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ü–ê–ú–Ø–¢–ò (–®–∞–≥ 5, 15, 126-150)
# ============================================================================

class MemorySystem:
    """
    –ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ MIRAI
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º–∏ —Ç–∏–ø–∞–º–∏ –ø–∞–º—è—Ç–∏ –∏ –∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ–º
    """
    
    def __init__(self, db_path: str = "data/memory_v3.db"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏
        
        Args:
            db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö SQLite
        """
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–º—è—Ç–∏
        self.short_term_memory: Optional[ShortTermMemory] = None
        self.working_memory: Optional[WorkingMemory] = None
        self.long_term_memory: Optional[LongTermMemory] = None
        self.episodic_memory: Optional[EpisodicMemory] = None
        self.semantic_memory: Optional[SemanticMemory] = None
        self.procedural_memory: Optional[ProceduralMemory] = None
        
        # –°–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.encoder: Optional[MemoryEncoder] = None
        self.retriever: Optional[MemoryRetriever] = None
        self.consolidator: Optional[MemoryConsolidation] = None
        self.indexer: Optional[MemoryIndexer] = None
        self.attention: Optional[AttentionMechanism] = None
        self.decay: Optional[MemoryDecay] = None
        self.reinforcement: Optional[MemoryReinforcement] = None
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
        self.experience_recorder: Optional[ExperienceRecorder] = None
        self.pattern_detector: Optional[PatternDetector] = None
        self.learning_engine: Optional[LearningEngine] = None
        self.knowledge_graph: Optional[KnowledgeGraph] = None
        self.vector_db: Optional[VectorDB] = None
        
        logger.info(f"‚úÖ MemorySystem –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.db_path}")
    
    def initialize(self, api_key: Optional[str] = None):
        """
        –ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –ø–æ–¥—Å–∏—Å—Ç–µ–º
        
        Args:
            api_key: OpenAI API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        logger.info("üöÄ –ù–∞—á–∞–ª–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏...")
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–º—è—Ç–∏
        self.short_term_memory = ShortTermMemory(capacity=20)
        self.working_memory = WorkingMemory()
        self.long_term_memory = LongTermMemory(str(self.db_path))
        self.episodic_memory = EpisodicMemory(self.long_term_memory)
        self.semantic_memory = SemanticMemory(self.long_term_memory)
        self.procedural_memory = ProceduralMemory(self.long_term_memory)
        
        # –°–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.encoder = MemoryEncoder(api_key)
        self.retriever = MemoryRetriever(self.long_term_memory, self.encoder)
        self.consolidator = MemoryConsolidation(
            self.short_term_memory,
            self.long_term_memory,
            self.encoder
        )
        self.indexer = MemoryIndexer(self.long_term_memory)
        self.attention = AttentionMechanism()
        self.decay = MemoryDecay(self.long_term_memory, half_life_days=30.0)
        self.reinforcement = MemoryReinforcement(self.long_term_memory)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
        self.experience_recorder = ExperienceRecorder(self)
        self.pattern_detector = PatternDetector(self)
        self.learning_engine = LearningEngine(self)
        self.knowledge_graph = KnowledgeGraph()
        self.vector_db = VectorDB()
        
        logger.info("‚úÖ –í—Å–µ –ø–æ–¥—Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!")
        
        return self
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏"""
        return {
            'short_term_size': len(self.short_term_memory) if self.short_term_memory else 0,
            'long_term_count': self.long_term_memory.count_memories() if self.long_term_memory else 0,
            'knowledge_graph_nodes': len(self.knowledge_graph.nodes) if self.knowledge_graph else 0,
            'knowledge_graph_edges': len(self.knowledge_graph.edges) if self.knowledge_graph else 0,
            'vector_db_size': len(self.vector_db) if self.vector_db else 0,
            'learned_rules': len(self.learning_engine.learned_rules) if self.learning_engine else 0,
            'detected_patterns': len(self.pattern_detector.detected_patterns) if self.pattern_detector else 0,
        }


# ============================================================================
# –®–ê–ì–ò 126-150: –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –ò –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø
# ============================================================================

class MemoryVisionIntegration:
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ –∑—Ä–µ–Ω–∏—è
    - –ü–∞–º—è—Ç—å –ø–æ–º–æ–≥–∞–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å —ç–∫—Ä–∞–Ω
    """
    
    def __init__(self, memory_system: MemorySystem):
        self.memory_system = memory_system
        logger.info("‚úÖ Memory-Vision Integration —Å–æ–∑–¥–∞–Ω–∞")
    
    def enhance_vision_with_memory(self, screen_analysis: Dict) -> Dict:
        """–£–ª—É—á—à–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —ç–∫—Ä–∞–Ω–∞ —Å –ø–æ–º–æ—â—å—é –ø–∞–º—è—Ç–∏"""
        if not self.memory_system.retriever:
            return screen_analysis
        
        similar_memories = self.memory_system.retriever.search_by_similarity(
            query=json.dumps(screen_analysis, ensure_ascii=False),
            top_k=5
        )
        
        screen_analysis['historical_context'] = [
            {
                'memory_id': mem.id,
                'similarity': score,
                'outcome': mem.content.get('result', {})
            }
            for mem, score in similar_memories
        ]
        
        return screen_analysis


class SuperAgentValidator:
    """
    –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–∞–ª–∏–¥–∞—Ç–æ—Ä MIRAI V3 SUPERAGENT
    –®–∞–≥ 150: –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã
    """
    
    def __init__(self, memory_system: MemorySystem):
        self.memory_system = memory_system
    
    def validate_all(self) -> Dict[str, bool]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        checks = {
            'short_term_memory': self.memory_system.short_term_memory is not None,
            'working_memory': self.memory_system.working_memory is not None,
            'long_term_memory': self.memory_system.long_term_memory is not None,
            'episodic_memory': self.memory_system.episodic_memory is not None,
            'semantic_memory': self.memory_system.semantic_memory is not None,
            'procedural_memory': self.memory_system.procedural_memory is not None,
            'encoder': self.memory_system.encoder is not None,
            'retriever': self.memory_system.retriever is not None,
            'consolidator': self.memory_system.consolidator is not None,
            'experience_recorder': self.memory_system.experience_recorder is not None,
            'pattern_detector': self.memory_system.pattern_detector is not None,
            'learning_engine': self.memory_system.learning_engine is not None,
            'knowledge_graph': self.memory_system.knowledge_graph is not None,
        }
        
        all_ok = all(checks.values())
        
        if all_ok:
            logger.info("=" * 70)
            logger.info("‚úÖ‚úÖ‚úÖ MIRAI V3 SUPERAGENT –ü–û–õ–ù–û–°–¢–¨–Æ –ì–û–¢–û–í! üöÄüöÄüöÄ")
            logger.info("=" * 70)
            logger.info("üìä Vision ‚úÖ + Reasoning ‚úÖ + Planning ‚úÖ")
            logger.info("‚ö° Execution ‚úÖ + Browser ‚úÖ + Apps ‚úÖ")
            logger.info("üß† Memory & Learning ‚úÖ")
            logger.info("=" * 70)
            logger.info("üéâ PRODUCTION READY! üéâ")
            logger.info("=" * 70)
        else:
            logger.error("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ –≥–æ—Ç–æ–≤—ã:")
            for component, status in checks.items():
                if not status:
                    logger.error(f"   ‚ùå {component}")
        
        return checks


# ============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò
# ============================================================================

def initialize_memory_system(db_path: str = "data/memory_v3.db", 
                            api_key: Optional[str] = None) -> MemorySystem:
    """
    –ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ Phase 7
    
    Args:
        db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        api_key: OpenAI API –∫–ª—é—á (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –ü–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è MemorySystem
    """
    system = MemorySystem(db_path)
    system.initialize(api_key)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    validator = SuperAgentValidator(system)
    validator.validate_all()
    
    return system


# ============================================================================
# –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø
# ============================================================================

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏"""
    logger.info("üéØ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ MIRAI V3 Memory System...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    memory_system = initialize_memory_system()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ –æ–ø—ã—Ç–∞
    logger.info("\nüìù –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–∏ –æ–ø—ã—Ç–∞...")
    experience_id = memory_system.experience_recorder.record_experience(
        event={'type': 'user_request', 'description': '–û—Ç–∫—Ä—ã—Ç—å –±—Ä–∞—É–∑–µ—Ä'},
        action={'type': 'open_chrome', 'parameters': {}},
        result={'success': True, 'confidence': 0.9},
        context={'user': 'test_user', 'timestamp': datetime.now().isoformat()}
    )
    logger.info(f"‚úÖ –û–ø—ã—Ç –∑–∞–ø–∏—Å–∞–Ω: {experience_id}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
    logger.info("\nüéì –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è...")
    memory_system.learning_engine.learn_from_experience(experience_id)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    logger.info("\nüîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...")
    patterns = memory_system.pattern_detector.detect_action_patterns(min_occurrences=1)
    logger.info(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(patterns)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏:")
    stats = memory_system.get_stats()
    for key, value in stats.items():
        logger.info(f"   {key}: {value}")
    
    # –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è
    logger.info("\nüí´ –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏...")
    consolidated = memory_system.consolidator.consolidate(threshold=0.5)
    logger.info(f"‚úÖ –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {consolidated}")
    
    logger.info("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    main()
