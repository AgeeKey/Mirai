#!/usr/bin/env python3
"""
üéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø: –†–µ–∞–ª—å–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ –≤ MIRAI
========================================================

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ù–û–í–´–ï –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ MIRAI:
1. ‚úÖ –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü (WebScraperAgent)
2. ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ —á–µ—Ä–µ–∑ Selenium (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
3. ‚úÖ –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

–ê–≤—Ç–æ—Ä: MIRAI Team
–î–∞—Ç–∞: 2025-10-25
"""

import asyncio
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent / "core"))

from web_scraper_agent import WebScraperAgent


async def demo_query_extraction():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É–º–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤"""
    print("\n" + "="*70)
    print("üìù –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø 1: –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
    print("="*70)
    
    agent = WebScraperAgent()
    
    # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –û–ø–µ—á–∞—Ç–∫–∏ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –ù–ê–ú–ï–†–ï–ù–ù–´–ï!
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    test_queries = [
        "–æ—Ç–∫—Ä—ã–π –±—Ä–∞—É–∑–µ—Ä –∏ –ø–æ–∏—â–∏ –∏—Ñ–æ—Ä–º–∞—Ç—Ü–∏—é –ø—Ä–æ—Å –±–∏–Ω–∞–Ω—Å –∏ —Ä–∞—Å—Å–∫–∞–∂–º–∏ –º–Ω–µ —á—Ç–æ —ç—Ç–æ –∑–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞",  # –ú–Ω–æ–≥–æ –æ–ø–µ—á–∞—Ç–æ–∫
        "–Ω–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–æ Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±—ä—è—Å–Ω–∏",
        "–ø–æ–∏—â–∏ —á—Ç–æ —Ç–∞–∫–æ–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞",
        "–∑–∞–≥—É–≥–ª–∏ React JS –∏ —Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ —á—Ç–æ —ç—Ç–æ",
    ]
    
    print("\nüîç –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Å –Ω–∞–º–µ—Ä–µ–Ω–Ω—ã–º–∏ –æ–ø–µ—á–∞—Ç–∫–∞–º–∏):\n")
    for query in test_queries:
        clean_query = agent.extract_search_query(query)
        print(f"üì• –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   \"{query}\"")
        print(f"‚ú® –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å:")
        print(f"   \"{clean_query}\"")
        print()
    
    agent.close()
    print("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 1 –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


async def demo_web_scraping():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    print("\n" + "="*70)
    print("üåê –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø 2: –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Google –∏ –ø–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–æ–≤")
    print("="*70)
    
    agent = WebScraperAgent()
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –±–µ–∑ AI –∞–Ω–∞–ª–∏–∑–∞ (–¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
    query = "Python programming language"
    print(f"\nüîç –ò—â–µ–º: {query}")
    print("‚è≥ –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫...")
    
    result = await agent.search_and_analyze(
        query,
        num_results=2,  # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ 2 —Å–∞–π—Ç–∞ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        analyze=False   # –û—Ç–∫–ª—é—á–∞–µ–º AI –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    )
    
    if result['success']:
        print(f"\n‚úÖ –ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {result['summary']['total_results']}")
        print(f"   ‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–∞–π—Ç–æ–≤: {result['summary']['scraped_pages']}")
        
        print(f"\nüìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ç–æ–ø-5):")
        for i, res in enumerate(result['search_results'][:5], 1):
            print(f"\n{i}. {res['title']}")
            print(f"   üîó {res['url']}")
            if res.get('snippet'):
                snippet = res['snippet'][:100] + "..." if len(res['snippet']) > 100 else res['snippet']
                print(f"   üìù {snippet}")
        
        if result['scraped_content']:
            print(f"\nüìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
            for i, content in enumerate(result['scraped_content'], 1):
                print(f"\n{i}. {content['title']}")
                print(f"   üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(content['content'])}")
                preview = content['content'][:200].replace('\n', ' ')
                print(f"   üìù –ü—Ä–µ–≤—å—é: {preview}...")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error')}")
    
    agent.close()
    print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


async def demo_selenium_automation():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Selenium (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
    print("\n" + "="*70)
    print("ü§ñ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø 3: –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ —á–µ—Ä–µ–∑ Selenium")
    print("="*70)
    
    try:
        from selenium_browser_agent import SeleniumBrowserAgent, SELENIUM_AVAILABLE
        
        if not SELENIUM_AVAILABLE:
            print("\n‚ö†Ô∏è Selenium –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
            print("üì¶ –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install selenium")
            print("üí° WebScraperAgent —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –±–µ–∑ Selenium!")
            return
        
        print("\nüöÄ –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞...")
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ë—Ä–∞—É–∑–µ—Ä –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –Ω–∞ 10 —Å–µ–∫—É–Ω–¥, –∑–∞—Ç–µ–º –∑–∞–∫—Ä–æ–µ—Ç—Å—è")
        
        agent = SeleniumBrowserAgent(headless=False)
        await agent.initialize()
        
        print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω!")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        query = "Python"
        print(f"\nüîç –ü–æ–∏—Å–∫ –≤ Google: {query}")
        result = await agent.search_google(query)
        
        if result['success']:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {result['count']}")
            print(f"\nüìã –¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
            for i, res in enumerate(result['results'][:3], 1):
                print(f"\n{i}. {res['title']}")
                print(f"   {res['url']}")
        
        # –°–∫—Ä–∏–Ω—à–æ—Ç
        print("\nüì∏ –°–æ–∑–¥–∞—ë–º —Å–∫—Ä–∏–Ω—à–æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞...")
        screenshot = await agent.take_screenshot("demo_search.png")
        if screenshot:
            print(f"‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {screenshot}")
        
        # –ñ–¥—ë–º –Ω–µ–º–Ω–æ–≥–æ —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–≤–∏–¥–µ–ª
        print("\n‚è≥ –ë—Ä–∞—É–∑–µ—Ä –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—ã–º 10 —Å–µ–∫—É–Ω–¥...")
        await asyncio.sleep(10)
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º
        await agent.close()
        print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 3 –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "‚ïî" + "="*68 + "‚ïó")
    print("‚ïë" + " "*15 + "üéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ù–û–í–´–• –í–û–ó–ú–û–ñ–ù–û–°–¢–ï–ô MIRAI" + " "*14 + "‚ïë")
    print("‚ïö" + "="*68 + "‚ïù")
    
    print("\nüåê –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –†–ï–ê–õ–¨–ù–£–Æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é –±—Ä–∞—É–∑–µ—Ä–∞:")
    print("   ‚úÖ –ü–æ–∏—Å–∫ –≤ Google")
    print("   ‚úÖ –ß—Ç–µ–Ω–∏–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü")
    print("   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
    print("   ‚úÖ AI –∞–Ω–∞–ª–∏–∑ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
    print("   ‚úÖ Selenium –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    await demo_query_extraction()
    await demo_web_scraping()
    
    # –°–ø—Ä–∞—à–∏–≤–∞–µ–º –ø—Ä–æ Selenium
    print("\n" + "="*70)
    response = input("\n‚ùì –•–æ—Ç–∏—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é Selenium? (–±—Ä–∞—É–∑–µ—Ä –æ—Ç–∫—Ä–æ–µ—Ç—Å—è) [y/N]: ")
    if response.lower() in ['y', 'yes', '–¥–∞', '–¥']:
        await demo_selenium_automation()
    else:
        print("‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Selenium –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é")
    
    print("\n" + "="*70)
    print("üéâ –í–°–ï –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò –ó–ê–í–ï–†–®–ï–ù–´!")
    print("="*70)
    
    print("\nüìù –ß—Ç–æ –±—ã–ª–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ:")
    print("   ‚úÖ –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ –∫–æ–º–∞–Ω–¥")
    print("   ‚úÖ –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Google —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º HTML")
    print("   ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —á—Ç–µ–Ω–∏–µ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü")
    print("   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML")
    if response.lower() in ['y', 'yes', '–¥–∞', '–¥']:
        print("   ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ —á–µ—Ä–µ–∑ Selenium")
        print("   ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
    
    print("\nüí° –¢–µ–ø–µ—Ä—å MIRAI - —ç—Ç–æ –ù–ê–°–¢–û–Ø–©–ò–ô AI –∞–≥–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π:")
    print("   ‚Ä¢ –ù–ï –ø—Ä–æ—Å—Ç–æ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä")
    print("   ‚Ä¢ –†–ï–ê–õ–¨–ù–û —á–∏—Ç–∞–µ—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    print("   ‚Ä¢ –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞")
    print("   ‚Ä¢ –ú–æ–∂–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    
    print("\nüöÄ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ unified_mirai.py!")
    print("   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: search_and_analyze_web")
    print("   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: automate_browser (–µ—Å–ª–∏ Selenium —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
    print()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
