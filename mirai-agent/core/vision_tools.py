"""
MIRAI Vision Tools - –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –¥–ª—è —É–º–Ω–æ–≥–æ AI –∞–≥–µ–Ω—Ç–∞
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —à–∞–≥, –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫
"""

import asyncio
import base64
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import pyautogui
from openai import OpenAI
import logging

logger = logging.getLogger(__name__)


@dataclass
class VisionContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≥–æ —á—Ç–æ –≤–∏–¥–∏—Ç –∞–≥–µ–Ω—Ç"""
    screenshot_path: str
    timestamp: datetime
    app_name: Optional[str] = None
    window_title: Optional[str] = None
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    scene_description: str = ""
    detected_elements: List[Dict] = None
    text_found: List[str] = None
    ui_state: Dict = None
    recommendations: List[str] = None
    
    def __post_init__(self):
        if self.detected_elements is None:
            self.detected_elements = []
        if self.text_found is None:
            self.text_found = []
        if self.ui_state is None:
            self.ui_state = {}
        if self.recommendations is None:
            self.recommendations = []


class VisionTools:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã Vision –¥–ª—è —É–º–Ω–æ–≥–æ AI –∞–≥–µ–Ω—Ç–∞.
    –ö–∞–∂–¥–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–∞–µ—Ç—Å—è –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    """
    
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
        self.screenshots_dir = Path("screenshots")
        self.screenshots_dir.mkdir(exist_ok=True)
        
    def capture_screen(self, region: str = 'full') -> str:
        """–°–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        filename = f"vision_{timestamp}.png"
        filepath = self.screenshots_dir / filename
        
        screenshot = pyautogui.screenshot()
        screenshot.save(str(filepath))
        
        logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")
        return str(filepath)
    
    def _encode_image(self, image_path: str) -> str:
        """–ó–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64"""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode('utf-8')
    
    async def analyze_screen_context(
        self, 
        screenshot_path: str,
        question: str = "–ß—Ç–æ —è –≤–∏–∂—É –Ω–∞ —ç–∫—Ä–∞–Ω–µ? –û–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, —ç–ª–µ–º–µ–Ω—Ç—ã, —Ç–µ–∫—Å—Ç.",
        app_name: Optional[str] = None,
        window_title: Optional[str] = None
    ) -> VisionContext:
        """
        –£–ú–ù–´–ô –ê–ù–ê–õ–ò–ó –≠–ö–†–ê–ù–ê –ö–ê–ö –ß–ï–õ–û–í–ï–ö.
        –ü–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, —ç–ª–µ–º–µ–Ω—Ç—ã UI, –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è.
        """
        
        context = VisionContext(
            screenshot_path=screenshot_path,
            timestamp=datetime.now(),
            app_name=app_name,
            window_title=window_title
        )
        
        # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        base64_image = self._encode_image(screenshot_path)
        
        # –£–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è GPT-4 Vision
        system_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤ –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º—É –∑—Ä–µ–Ω–∏—é.
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø–æ–Ω—è—Ç—å –ß–¢–û –≤–∏–¥–∏—Ç AI –∞–≥–µ–Ω—Ç –∏ –ö–ê–ö —Å —ç—Ç–∏–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞–∫ —á–µ–ª–æ–≤–µ–∫:
        1. –ö–∞–∫–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/—Å–∞–π—Ç –æ—Ç–∫—Ä—ã—Ç?
        2. –ö–∞–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤–∏–¥–Ω—ã? (–∫–Ω–æ–ø–∫–∏, –ø–æ–ª—è, –º–µ–Ω—é)
        3. –ì–¥–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤–∞–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã? (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –Ω—É–∂–Ω—ã, –ø—Ä–æ—Å—Ç–æ "—Å–≤–µ—Ä—Ö—É —Å–ª–µ–≤–∞", "–≤ —Ü–µ–Ω—Ç—Ä–µ")
        4. –ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –≤–∏–¥–µ–Ω –Ω–∞ —ç–∫—Ä–∞–Ω–µ?
        5. –ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –°–ï–ô–ß–ê–°? (–¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è)
        6. –ï—Å—Ç—å –ª–∏ –ø—Ä–æ–±–ª–µ–º—ã? (–æ—à–∏–±–∫–∏, —Ä–µ–∫–ª–∞–º—ã, –ø–æ–ø–∞–ø—ã, –≤—ã–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è)
        
        –û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
        {
            "scene": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —á—Ç–æ –≤–∏–¥–Ω–æ",
            "app_detected": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è",
            "elements": [
                {"type": "button", "label": "—Ç–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏", "location": "–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è"},
                {"type": "textfield", "label": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è", "location": "–≥–¥–µ"}
            ],
            "text_visible": ["—Ç–µ–∫—Å—Ç1", "—Ç–µ–∫—Å—Ç2"],
            "possible_actions": ["–¥–µ–π—Å—Ç–≤–∏–µ1", "–¥–µ–π—Å—Ç–≤–∏–µ2"],
            "problems_detected": ["–ø—Ä–æ–±–ª–µ–º–∞1 –µ—Å–ª–∏ –µ—Å—Ç—å"],
            "recommendations": ["—á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ"]
        }
        """
        
        user_prompt = f"""–í–æ–ø—Ä–æ—Å: {question}

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
- –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: {app_name or '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}
- –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ–∫–Ω–∞: {window_title or '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–∫—Ä–∏–Ω—à–æ—Ç –∏ –æ—Ç–≤–µ—Ç—å –≤ JSON."""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": user_prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=2000,
                temperature=0.3  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # –ü–∞—Ä—Å–∏–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            # –ò–Ω–æ–≥–¥–∞ GPT –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç + JSON, –∏–∑–≤–ª–µ–∫–∞–µ–º JSON
            if "```json" in result_text:
                result_text = result_text.split("```json")[1].split("```")[0].strip()
            elif "```" in result_text:
                result_text = result_text.split("```")[1].split("```")[0].strip()
            
            analysis = json.loads(result_text)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context.scene_description = analysis.get("scene", "")
            context.detected_elements = analysis.get("elements", [])
            context.text_found = analysis.get("text_visible", [])
            context.ui_state = {
                "app": analysis.get("app_detected", ""),
                "possible_actions": analysis.get("possible_actions", []),
                "problems": analysis.get("problems_detected", [])
            }
            context.recommendations = analysis.get("recommendations", [])
            
            logger.info(f"üß† Vision –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω: {context.scene_description[:100]}")
            
            return context
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Vision –∞–Ω–∞–ª–∏–∑–∞: {e}")
            context.scene_description = f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}"
            return context
    
    async def find_element_on_screen(
        self,
        screenshot_path: str,
        element_description: str,
        app_name: Optional[str] = None
    ) -> Optional[Dict]:
        """
        –ù–ê–ô–¢–ò –ö–û–ù–ö–†–ï–¢–ù–´–ô –≠–õ–ï–ú–ï–ù–¢ –ù–ê –≠–ö–†–ê–ù–ï (–∫–Ω–æ–ø–∫—É, –ø–æ–ª–µ –≤–≤–æ–¥–∞ –∏ —Ç.–¥.)
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∏ –∫–∞–∫ —Å –Ω–∏–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å.
        """
        
        base64_image = self._encode_image(screenshot_path)
        
        prompt = f"""–ù–∞–π–¥–∏ –Ω–∞ —ç–∫—Ä–∞–Ω–µ: {element_description}

–û–ø–∏—à–∏ –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —ç—Ç–æ—Ç —ç–ª–µ–º–µ–Ω—Ç (—Å–≤–µ—Ä—Ö—É/—Å–Ω–∏–∑—É/—Å–ª–µ–≤–∞/—Å–ø—Ä–∞–≤–∞/–≤ —Ü–µ–Ω—Ç—Ä–µ).
–≠—Ç–æ –∫–Ω–æ–ø–∫–∞, –ø–æ–ª–µ –≤–≤–æ–¥–∞, —Å—Å—ã–ª–∫–∞ –∏–ª–∏ —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ?
–ö–∞–∫–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ —ç—Ç–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ?

–û—Ç–≤–µ—Ç—å –≤ JSON:
{{
    "found": true/false,
    "element_type": "button/textfield/link/menu/other",
    "label": "—Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞",
    "location": "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è",
    "how_to_interact": "–∫–∞–∫ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å (click/type/select)"
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.2
            )
            
            result = response.choices[0].message.content.strip()
            
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0].strip()
            
            element_info = json.loads(result)
            
            if element_info.get("found"):
                logger.info(f"‚úÖ –≠–ª–µ–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω: {element_info.get('label')} ({element_info.get('location')})")
                return element_info
            else:
                logger.warning(f"‚ùå –≠–ª–µ–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {element_description}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            return None
    
    async def verify_action_result(
        self,
        before_screenshot: str,
        after_screenshot: str,
        intended_action: str
    ) -> Dict:
        """
        –ü–†–û–í–ï–†–ò–¢–¨ –ß–¢–û –î–ï–ô–°–¢–í–ò–ï –í–´–ü–û–õ–ù–ò–õ–û–°–¨ –ü–†–ê–í–ò–õ–¨–ù–û.
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç "–¥–æ" –∏ "–ø–æ—Å–ª–µ", –ø–æ–Ω–∏–º–∞–µ—Ç —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å.
        """
        
        before_image = self._encode_image(before_screenshot)
        after_image = self._encode_image(after_screenshot)
        
        prompt = f"""–î–µ–π—Å—Ç–≤–∏–µ –±—ã–ª–æ: {intended_action}

–°—Ä–∞–≤–Ω–∏ –î–û –∏ –ü–û–°–õ–ï. –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å? –í—ã–ø–æ–ª–Ω–∏–ª–æ—Å—å –ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ —É—Å–ø–µ—à–Ω–æ?

–û—Ç–≤–µ—Ç—å –≤ JSON:
{{
    "success": true/false,
    "changes_detected": "—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å",
    "action_completed": true/false,
    "problems": ["–ø—Ä–æ–±–ª–µ–º—ã –µ—Å–ª–∏ –µ—Å—Ç—å"],
    "next_steps": ["—á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ"]
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "–°–∫—Ä–∏–Ω—à–æ—Ç –î–û –¥–µ–π—Å—Ç–≤–∏—è:"},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{before_image}"}
                            },
                            {"type": "text", "text": "–°–∫—Ä–∏–Ω—à–æ—Ç –ü–û–°–õ–ï –¥–µ–π—Å—Ç–≤–∏—è:"},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{after_image}"}
                            },
                            {"type": "text", "text": prompt}
                        ]
                    }
                ],
                max_tokens=800,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0].strip()
            
            verification = json.loads(result)
            
            if verification.get("success"):
                logger.info(f"‚úÖ –î–µ–π—Å—Ç–≤–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {verification.get('changes_detected')}")
            else:
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {verification.get('problems')}")
            
            return verification
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            return {
                "success": False,
                "changes_detected": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å",
                "problems": [str(e)]
            }
    
    async def detect_problems(self, screenshot_path: str) -> List[str]:
        """
        –û–ë–ù–ê–†–£–ñ–ò–¢–¨ –ü–†–û–ë–õ–ï–ú–´: —Ä–µ–∫–ª–∞–º–∞, –æ—à–∏–±–∫–∏, –ø–æ–ø–∞–ø—ã, –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –æ–∫–Ω–∞.
        """
        
        base64_image = self._encode_image(screenshot_path)
        
        prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç–∫—Ä–∞–Ω –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ü–†–û–ë–õ–ï–ú:
        - –†–µ–∫–ª–∞–º–∞ (–±–∞–Ω–Ω–µ—Ä—ã, –ø–æ–ø–∞–ø—ã)
        - –û—à–∏–±–∫–∏ (—Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ)
        - –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –æ–∫–Ω–∞ (–≤—ã–±–æ—Ä –ø—Ä–æ—Ñ–∏–ª—è, –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
        - –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–µ–π—Å—Ç–≤–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
        
        –û—Ç–≤–µ—Ç—å —Å–ø–∏—Å–∫–æ–º JSON:
        ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"] –∏–ª–∏ [] –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                            }
                        ]
                    }
                ],
                max_tokens=300,
                temperature=0.2
            )
            
            result = response.choices[0].message.content.strip()
            
            if "```json" in result:
                result = result.split("```json")[1].split("```")[0].strip()
            elif "```" in result:
                result = result.split("```")[1].split("```")[0].strip()
            
            problems = json.loads(result)
            
            if problems:
                logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã: {problems}")
            else:
                logger.info("‚úÖ –ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
            
            return problems
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º: {e}")
            return []
