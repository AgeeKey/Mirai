#!/usr/bin/env python3
"""
üéØ –†–ï–ê–õ–¨–ù–´–ï –ó–∞–¥–∞—á–∏ –¥–ª—è MIRAI
–ó–∞–º–µ–Ω–∞ "TODO" –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è —Å –∏–∑–º–µ—Ä–∏–º—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
"""

import json
import os
import re
import subprocess
from collections import Counter
from datetime import datetime
from pathlib import Path
from typing import Dict, List


class RealTaskExecutor:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤–º–µ—Å—Ç–æ TODO"""

    def __init__(self, base_dir: str = "/root/mirai"):
        self.base_dir = Path(base_dir)
        self.reports_dir = self.base_dir / "reports"
        self.metrics_dir = self.base_dir / "metrics"
        self.knowledge_dir = self.base_dir / "knowledge_base"

        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.reports_dir.mkdir(exist_ok=True)
        self.metrics_dir.mkdir(exist_ok=True)
        self.knowledge_dir.mkdir(exist_ok=True)

    def task1_analyze_logs_and_report(self) -> Dict:
        """
        –ó–ê–î–ê–ß–ê 1: –ê–Ω–∞–ª–∏–∑ –õ–æ–≥–æ–≤ –∏ –°–æ–∑–¥–∞–Ω–∏–µ –û—Ç—á—ë—Ç–∞

        –ò–∑–º–µ—Ä–∏–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –§–∞–π–ª reports/daily_analysis_YYYY-MM-DD.md —Å–æ–∑–¥–∞–Ω
        """
        print("üîç –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤...")

        # –ß–∏—Ç–∞–µ–º –ª–æ–≥–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        logs = self._read_journalctl_logs(since="24 hours ago")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        analysis = self._analyze_logs(logs)

        # –°–æ–∑–¥–∞—ë–º –æ—Ç—á—ë—Ç
        report_date = datetime.now().strftime("%Y-%m-%d")
        report_content = self._generate_report(analysis, report_date)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç
        report_file = self.reports_dir / f"daily_analysis_{report_date}.md"
        report_file.write_text(report_content, encoding="utf-8")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_file = self.reports_dir / f"daily_stats_{report_date}.json"
        stats_file.write_text(
            json.dumps(analysis, indent=2, ensure_ascii=False), encoding="utf-8"
        )

        result = {
            "task": "analyze_logs_and_report",
            "status": "COMPLETED",
            "timestamp": datetime.now().isoformat(),
            "report_file": str(report_file),
            "stats_file": str(stats_file),
            "summary": {
                "total_lines": analysis["total_lines"],
                "errors": analysis["error_count"],
                "warnings": analysis["warning_count"],
                "autonomous_cycles": analysis["autonomous_cycles"],
            },
        }

        print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: {report_file}")
        print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats_file}")

        return result

    def _read_journalctl_logs(self, since: str = "24 hours ago") -> List[str]:
        """–ß–∏—Ç–∞–µ—Ç –ª–æ–≥–∏ –∏–∑ journalctl"""
        try:
            cmd = ["sudo", "journalctl", "-u", "mirai", "--since", since, "--no-pager"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                return result.stdout.split("\n")
            else:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–≥–æ–≤: {result.stderr}")
                return []
        except Exception as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–æ–≥–∏: {e}")
            return []

    def _analyze_logs(self, logs: List[str]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""

        analysis = {
            "total_lines": len(logs),
            "error_count": 0,
            "warning_count": 0,
            "info_count": 0,
            "autonomous_cycles": 0,
            "todo_count": 0,
            "errors": [],
            "warnings": [],
            "top_messages": [],
            "cycle_numbers": [],
            "timestamp_first": None,
            "timestamp_last": None,
        }

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
        error_pattern = re.compile(
            r"(ERROR|error|–æ—à–∏–±–∫–∞|failed|failure)", re.IGNORECASE
        )
        warning_pattern = re.compile(r"(WARNING|warning|–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)", re.IGNORECASE)
        cycle_pattern = re.compile(r"–ê–í–¢–û–ù–û–ú–ù–´–ô –¶–ò–ö–õ #(\d+)")
        todo_pattern = re.compile(r"TODO:", re.IGNORECASE)

        message_counter = Counter()

        for line in logs:
            if not line.strip():
                continue

            # –°—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫–∏
            if error_pattern.search(line):
                analysis["error_count"] += 1
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫
                if len(analysis["errors"]) < 10:
                    error_msg = line.split(":", 3)[-1].strip()[:200]
                    if error_msg and error_msg not in analysis["errors"]:
                        analysis["errors"].append(error_msg)

            # –°—á–∏—Ç–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            if warning_pattern.search(line):
                analysis["warning_count"] += 1
                if len(analysis["warnings"]) < 10:
                    warn_msg = line.split(":", 3)[-1].strip()[:200]
                    if warn_msg and warn_msg not in analysis["warnings"]:
                        analysis["warnings"].append(warn_msg)

            # –°—á–∏—Ç–∞–µ–º —Ü–∏–∫–ª—ã
            cycle_match = cycle_pattern.search(line)
            if cycle_match:
                analysis["autonomous_cycles"] += 1
                cycle_num = int(cycle_match.group(1))
                analysis["cycle_numbers"].append(cycle_num)

            # –°—á–∏—Ç–∞–µ–º TODO
            if todo_pattern.search(line):
                analysis["todo_count"] += 1

            # –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            if any(
                keyword in line
                for keyword in ["ü§ñ", "üå∏", "‚úÖ", "‚ùå", "–ö–ê–ô–î–ó–ï–ù", "MIRAI"]
            ):
                msg = line.split(":", 3)[-1].strip()[:100]
                if msg:
                    message_counter[msg] += 1

            # INFO —Å–æ–æ–±—â–µ–Ω–∏—è
            if "INFO" in line or "info" in line:
                analysis["info_count"] += 1

        # –¢–æ–ø —Å–æ–æ–±—â–µ–Ω–∏–π
        analysis["top_messages"] = [
            {"message": msg, "count": count}
            for msg, count in message_counter.most_common(10)
        ]

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        if logs:
            for line in logs:
                if line.strip():
                    analysis["timestamp_first"] = line.split()[0:3]
                    break
            for line in reversed(logs):
                if line.strip():
                    analysis["timestamp_last"] = line.split()[0:3]
                    break

        return analysis

    def _generate_report(self, analysis: Dict, date: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –æ—Ç—á—ë—Ç"""

        report = f"""# üìä –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ê–Ω–∞–ª–∏–∑ –õ–æ–≥–æ–≤ MIRAI

**–î–∞—Ç–∞:** {date}
**–ü–µ—Ä–∏–æ–¥:** –ü–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
**–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

## üìà –û–±—â–∞—è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- **–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤:** {analysis['total_lines']:,}
- **–û—à–∏–±–∫–∏:** {analysis['error_count']:,}
- **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:** {analysis['warning_count']:,}
- **–ò–Ω—Ñ–æ —Å–æ–æ–±—â–µ–Ω–∏—è:** {analysis['info_count']:,}
- **–ê–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤:** {analysis['autonomous_cycles']:,}
- **TODO –∑–∞–ø–∏—Å–µ–π:** {analysis['todo_count']:,}

---

## üî¥ –¢–æ–ø –û—à–∏–±–æ–∫

"""

        if analysis["errors"]:
            for i, error in enumerate(analysis["errors"], 1):
                report += f"{i}. `{error}`\n"
        else:
            report += "*–û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ* ‚úÖ\n"

        report += "\n---\n\n## ‚ö†Ô∏è –¢–æ–ø –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π\n\n"

        if analysis["warnings"]:
            for i, warning in enumerate(analysis["warnings"], 1):
                report += f"{i}. `{warning}`\n"
        else:
            report += "*–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ* ‚úÖ\n"

        report += "\n---\n\n## üí¨ –¢–æ–ø –°–æ–æ–±—â–µ–Ω–∏–π (–ß–∞—Å—Ç–æ—Ç–∞)\n\n"

        for item in analysis["top_messages"][:5]:
            report += f"- `{item['message']}` - **{item['count']}** —Ä–∞–∑\n"

        report += "\n---\n\n## üîÑ –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –¶–∏–∫–ª—ã\n\n"

        if analysis["cycle_numbers"]:
            report += f"- **–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ü–∏–∫–ª:** #{min(analysis['cycle_numbers'])}\n"
            report += f"- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ü–∏–∫–ª:** #{max(analysis['cycle_numbers'])}\n"
            report += (
                f"- **–í—Å–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:** {len(analysis['cycle_numbers'])} —Ü–∏–∫–ª–æ–≤\n"
            )
        else:
            report += "*–¶–∏–∫–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*\n"

        report += "\n---\n\n## üö® TODO –ü—Ä–æ–±–ª–µ–º–∞\n\n"

        if analysis["todo_count"] > 0:
            report += (
                f"‚ö†Ô∏è **–í–ù–ò–ú–ê–ù–ò–ï:** –ù–∞–π–¥–µ–Ω–æ {analysis['todo_count']} –∑–∞–ø–∏—Å–µ–π TODO!\n\n"
            )
            report += "–≠—Ç–æ –∑–Ω–∞—á–∏—Ç —á—Ç–æ MIRAI –ª–æ–≥–∏—Ä—É–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏—è, –Ω–æ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏—Ö.\n"
            report += "**–¢—Ä–µ–±—É–µ—Ç—Å—è:** –ó–∞–º–µ–Ω–∏—Ç—å TODO –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—é.\n"
        else:
            report += "‚úÖ TODO –∑–∞–ø–∏—Å–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - MIRAI —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!\n"

        report += "\n---\n\n## üìä –û—Ü–µ–Ω–∫–∞ –ó–¥–æ—Ä–æ–≤—å—è\n\n"

        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫—É –∑–¥–æ—Ä–æ–≤—å—è
        health_score = 100

        if analysis["error_count"] > 10:
            health_score -= 30
        elif analysis["error_count"] > 5:
            health_score -= 15

        if analysis["todo_count"] > 10:
            health_score -= 20
        elif analysis["todo_count"] > 5:
            health_score -= 10

        if analysis["warning_count"] > 20:
            health_score -= 10

        if analysis["autonomous_cycles"] == 0:
            health_score -= 40

        if health_score >= 90:
            grade = "üü¢ –û–¢–õ–ò–ß–ù–û"
        elif health_score >= 70:
            grade = "üü° –•–û–†–û–®–û"
        elif health_score >= 50:
            grade = "üü† –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û"
        else:
            grade = "üî¥ –¢–†–ï–ë–£–ï–¢ –í–ù–ò–ú–ê–ù–ò–Ø"

        report += f"**–û—Ü–µ–Ω–∫–∞:** {health_score}/100 - {grade}\n\n"

        report += "---\n\n*–û—Ç—á—ë—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ MIRAI Real Task Executor*\n"

        return report

    def task2_monitor_cicd_and_create_issue(self, health_data: Dict) -> Dict:
        """
        –ó–ê–î–ê–ß–ê 2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ CI/CD –∏ –°–æ–∑–¥–∞–Ω–∏–µ GitHub Issue

        –ò–∑–º–µ—Ä–∏–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: Issue —Å–æ–∑–¥–∞–Ω –≤ GitHub –∏–ª–∏ –∑–∞–ø–∏—Å–∞–Ω –≤ —Ñ–∞–π–ª
        """
        print("üîç –ú–æ–Ω–∏—Ç–æ—Ä—é CI/CD –∏ —Å–æ–∑–¥–∞—é issue –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö...")

        status = health_data.get("status", "UNKNOWN")
        grade = health_data.get("grade", "N/A")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—á—ë—Ç—á–∏–∫ –ø—Ä–æ–±–ª–µ–º
        counter_file = self.metrics_dir / "cicd_unhealthy_counter.json"

        if counter_file.exists():
            counter_data = json.loads(counter_file.read_text())
            count = counter_data.get("count", 0)
            last_issue_date = counter_data.get("last_issue_date", None)
        else:
            count = 0
            last_issue_date = None

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –µ—Å–ª–∏ unhealthy
        if status == "UNHEALTHY":
            count += 1
        else:
            count = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –µ—Å–ª–∏ –∑–¥–æ—Ä–æ–≤

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—á—ë—Ç—á–∏–∫
        counter_data = {
            "count": count,
            "last_check": datetime.now().isoformat(),
            "last_issue_date": last_issue_date,
        }
        counter_file.write_text(json.dumps(counter_data, indent=2))

        # –°–æ–∑–¥–∞—ë–º issue –µ—Å–ª–∏ 3+ —Ä–∞–∑–∞ unhealthy –ø–æ–¥—Ä—è–¥
        if count >= 3 and (
            not last_issue_date
            or (datetime.now() - datetime.fromisoformat(last_issue_date)).days >= 1
        ):

            issue_data = self._create_cicd_issue_file(health_data, count)

            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ issue
            counter_data["last_issue_date"] = datetime.now().isoformat()
            counter_data["count"] = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è issue
            counter_file.write_text(json.dumps(counter_data, indent=2))

            result = {
                "task": "monitor_cicd_and_create_issue",
                "status": "ISSUE_CREATED",
                "timestamp": datetime.now().isoformat(),
                "issue_file": issue_data["file"],
                "unhealthy_count": count,
                "action": "Issue created due to persistent problems",
            }
            print(f"‚úÖ Issue —Å–æ–∑–¥–∞–Ω: {issue_data['file']}")
        else:
            result = {
                "task": "monitor_cicd_and_create_issue",
                "status": "MONITORING",
                "timestamp": datetime.now().isoformat(),
                "unhealthy_count": count,
                "action": f"Monitoring (need {3-count} more to create issue)",
            }
            print(f"üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {count}/3 –ø—Ä–æ–±–ª–µ–º")

        return result

    def _create_cicd_issue_file(self, health_data: Dict, count: int) -> Dict:
        """–°–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ issue"""
        issues_dir = self.base_dir / "issues"
        issues_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        issue_file = issues_dir / f"cicd_problem_{timestamp}.json"

        issue_content = {
            "title": f"üî¥ CI/CD Unhealthy: {health_data.get('grade', 'N/A')}",
            "body": f"""
## Problem Details

CI/CD pipeline has been unhealthy {count} times in a row.

**Status:** {health_data.get('status', 'UNKNOWN')}
**Grade:** {health_data.get('grade', 'N/A')}
**Success Rate:** {health_data.get('success_rate', 'N/A')}

## Recent Runs

{health_data.get('report', 'No report available')}

## Action Required

Please investigate and fix the failing tests or workflows.

---
*Auto-generated by MIRAI Real Task Executor*
""",
            "labels": ["bug", "ci-cd", "automated"],
            "created_at": datetime.now().isoformat(),
            "unhealthy_count": count,
        }

        issue_file.write_text(json.dumps(issue_content, indent=2, ensure_ascii=False))

        return {"file": str(issue_file), "content": issue_content}

    def task3_build_knowledge_base(self) -> Dict:
        """
        –ó–ê–î–ê–ß–ê 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ë–∞–∑—ã –ó–Ω–∞–Ω–∏–π –∏–∑ –õ–æ–≥–æ–≤

        –ò–∑–º–µ—Ä–∏–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: knowledge_base/errors.json –æ–±–Ω–æ–≤–ª—ë–Ω
        """
        print("üìö –°—Ç—Ä–æ—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫...")

        # –ß–∏—Ç–∞–µ–º –ª–æ–≥–∏ –∑–∞ –Ω–µ–¥–µ–ª—é
        logs = self._read_journalctl_logs(since="7 days ago")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—à–∏–±–∫–∏
        error_patterns = self._extract_error_patterns(logs)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        kb_file = self.knowledge_dir / "errors.json"

        if kb_file.exists():
            kb = json.loads(kb_file.read_text())
        else:
            kb = {
                "error_patterns": {},
                "last_updated": None,
                "total_errors_analyzed": 0,
            }

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern, data in error_patterns.items():
            if pattern in kb["error_patterns"]:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
                kb["error_patterns"][pattern]["count"] += data["count"]
                kb["error_patterns"][pattern]["last_seen"] = data["last_seen"]
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
                kb["error_patterns"][pattern] = data

        kb["last_updated"] = datetime.now().isoformat()
        kb["total_errors_analyzed"] = sum(
            p["count"] for p in kb["error_patterns"].values()
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        kb_file.write_text(json.dumps(kb, indent=2, ensure_ascii=False))

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º FAQ
        faq_file = self.knowledge_dir / "FAQ.md"
        faq_content = self._generate_faq_from_kb(kb)
        faq_file.write_text(faq_content)

        result = {
            "task": "build_knowledge_base",
            "status": "COMPLETED",
            "timestamp": datetime.now().isoformat(),
            "kb_file": str(kb_file),
            "faq_file": str(faq_file),
            "summary": {
                "unique_patterns": len(kb["error_patterns"]),
                "total_errors": kb["total_errors_analyzed"],
                "new_patterns": len(error_patterns),
            },
        }

        print(f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {len(kb['error_patterns'])} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print(f"‚úÖ FAQ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {faq_file}")

        return result

    def _extract_error_patterns(self, logs: List[str]) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫ –∏–∑ –ª–æ–≥–æ–≤"""
        patterns = {}

        error_regex = re.compile(r"(ERROR|error|–æ—à–∏–±–∫–∞|failed|failure)", re.IGNORECASE)

        for line in logs:
            if error_regex.search(line):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—Ç—å –æ—à–∏–±–∫–∏ (—É–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                error_msg = line.split(":", 3)[-1].strip()[:150]

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º (—É–±–∏—Ä–∞–µ–º —á–∏—Å–ª–∞, –ø—É—Ç–∏ –∏ —Ç.–¥.)
                normalized = re.sub(r"\d+", "N", error_msg)
                normalized = re.sub(r"/[\w/]+", "/PATH", normalized)

                if normalized and len(normalized) > 20:
                    if normalized in patterns:
                        patterns[normalized]["count"] += 1
                    else:
                        patterns[normalized] = {
                            "count": 1,
                            "example": error_msg,
                            "first_seen": datetime.now().isoformat(),
                            "last_seen": datetime.now().isoformat(),
                        }

        return patterns

    def _generate_faq_from_kb(self, kb: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç FAQ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        faq = f"""# ü§î FAQ - –ß–∞—Å—Ç—ã–µ –û—à–∏–±–∫–∏ –∏ –†–µ—à–µ–Ω–∏—è

**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ:** {kb['total_errors_analyzed']:,}
**–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:** {len(kb['error_patterns'])}

---

## –¢–æ–ø-10 –ß–∞—Å—Ç—ã—Ö –û—à–∏–±–æ–∫

"""

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
        sorted_patterns = sorted(
            kb["error_patterns"].items(), key=lambda x: x[1]["count"], reverse=True
        )[:10]

        for i, (pattern, data) in enumerate(sorted_patterns, 1):
            faq += f"""
### {i}. –û—à–∏–±–∫–∞ (–≤—Å—Ç—Ä–µ—á–∞–ª–∞—Å—å {data['count']} —Ä–∞–∑)

**–ü–∞—Ç—Ç–µ—Ä–Ω:** `{pattern[:100]}`

**–ü—Ä–∏–º–µ—Ä:**
```
{data['example']}
```

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –ø–æ—è–≤–ª–µ–Ω–∏–µ:** {data['last_seen']}

**–í–æ–∑–º–æ–∂–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:** 
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π
- –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é

---
"""

        faq += "\n*FAQ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω MIRAI Real Task Executor*\n"

        return faq

    def task4_update_metrics_dashboard(self) -> Dict:
        """
        –ó–ê–î–ê–ß–ê 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ú–µ—Ç—Ä–∏–∫ –∏ Dashboard

        –ò–∑–º–µ—Ä–∏–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: metrics/latest.json –∏ web/dashboard.html –æ–±–Ω–æ–≤–ª–µ–Ω—ã
        """
        print("üìä –û–±–Ω–æ–≤–ª—è—é –º–µ—Ç—Ä–∏–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é dashboard...")

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = self._collect_current_metrics()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics_file = self.metrics_dir / "latest.json"
        metrics_file.write_text(json.dumps(metrics, indent=2, ensure_ascii=False))

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        history_file = self.metrics_dir / "history.jsonl"
        with open(history_file, "a") as f:
            f.write(json.dumps(metrics, ensure_ascii=False) + "\n")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML dashboard
        web_dir = self.base_dir / "web"
        web_dir.mkdir(exist_ok=True)

        dashboard_file = web_dir / "dashboard.html"
        dashboard_html = self._generate_dashboard_html(metrics)
        dashboard_file.write_text(dashboard_html)

        result = {
            "task": "update_metrics_dashboard",
            "status": "COMPLETED",
            "timestamp": datetime.now().isoformat(),
            "metrics_file": str(metrics_file),
            "dashboard_file": str(dashboard_file),
            "summary": metrics,
        }

        print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã: {metrics_file}")
        print(f"‚úÖ Dashboard —Å–æ–∑–¥–∞–Ω: {dashboard_file}")

        return result

    def _collect_current_metrics(self) -> Dict:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ journalctl
        logs = self._read_journalctl_logs(since="1 hour ago")

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–∏–∫–ª—ã
        cycles = len([l for l in logs if "–ê–í–¢–û–ù–û–ú–ù–´–ô –¶–ò–ö–õ" in l])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ë–î
        db_file = self.base_dir / "mirai-agent" / "data" / "mirai_memory.db"
        db_size = db_file.stat().st_size if db_file.exists() else 0

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "cycles_last_hour": cycles,
            "db_size_bytes": db_size,
            "db_size_human": self._human_readable_size(db_size),
            "log_lines_last_hour": len(logs),
            "errors_last_hour": len([l for l in logs if "ERROR" in l or "error" in l]),
            "warnings_last_hour": len(
                [l for l in logs if "WARNING" in l or "warning" in l]
            ),
        }

        return metrics

    def _human_readable_size(self, size_bytes: int) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–∞–π—Ç—ã –≤ —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        size = float(size_bytes)
        for unit in ["B", "KB", "MB", "GB"]:
            if size < 1024.0:
                return f"{size:.1f} {unit}"
            size /= 1024.0
        return f"{size:.1f} TB"

    def _generate_dashboard_html(self, metrics: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML dashboard"""

        html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MIRAI Dashboard</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0;
            padding: 20px;
            color: #333;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
        }}
        h1 {{
            color: #667eea;
            text-align: center;
            margin-bottom: 10px;
        }}
        .timestamp {{
            text-align: center;
            color: #666;
            margin-bottom: 30px;
        }}
        .metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        .metric-card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }}
        .metric-label {{
            font-size: 14px;
            opacity: 0.9;
            margin-bottom: 5px;
        }}
        .metric-value {{
            font-size: 32px;
            font-weight: bold;
        }}
        .status {{
            padding: 10px 20px;
            border-radius: 20px;
            display: inline-block;
            margin: 10px 0;
        }}
        .status-ok {{
            background: #4caf50;
            color: white;
        }}
        .status-warning {{
            background: #ff9800;
            color: white;
        }}
        .footer {{
            text-align: center;
            margin-top: 30px;
            color: #666;
            font-size: 12px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ü§ñ MIRAI Dashboard</h1>
        <div class="timestamp">–û–±–Ω–æ–≤–ª–µ–Ω–æ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</div>
        
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-label">–¶–∏–∫–ª—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å)</div>
                <div class="metric-value">{metrics.get('cycles_last_hour', 0)}</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-label">–†–∞–∑–º–µ—Ä –ë–î</div>
                <div class="metric-value">{metrics.get('db_size_human', 'N/A')}</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-label">–°—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤</div>
                <div class="metric-value">{metrics.get('log_lines_last_hour', 0):,}</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-label">–û—à–∏–±–∫–∏</div>
                <div class="metric-value">{metrics.get('errors_last_hour', 0)}</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-label">–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è</div>
                <div class="metric-value">{metrics.get('warnings_last_hour', 0)}</div>
            </div>
        </div>
        
        <div style="text-align: center;">
            <span class="status {'status-ok' if metrics.get('errors_last_hour', 0) == 0 else 'status-warning'}">
                {'‚úÖ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ' if metrics.get('errors_last_hour', 0) == 0 else '‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏'}
            </span>
        </div>
        
        <div class="footer">
            Auto-generated by MIRAI Real Task Executor<br>
            Next update: {(datetime.now()).strftime("%H:%M")}
        </div>
    </div>
</body>
</html>
"""

        return html

    def task5_auto_fix_code(self, issue_description: str | None = None) -> Dict:
        """
        –ó–ê–î–ê–ß–ê 5: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ö–æ–¥–∞

        –ü–æ—Ç–æ–∫:
        1. AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        2. –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é –≤–µ—Ç–∫—É –≤ GitHub
        3. –ö–æ–º–º–∏—Ç–∏—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥
        4. –°–æ–∑–¥–∞—ë—Ç Pull Request —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º

        –ò–∑–º–µ—Ä–∏–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: PR —Å–æ–∑–¥–∞–Ω –≤ GitHub
        """
        print("ü§ñ –ù–∞—á–∏–Ω–∞—é –∞–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∞...")

        try:
            from core.autonomous_agent import AutonomousAgent
            from core.github_integration import GitHubIntegration

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            agent = AutonomousAgent()
            gh = GitHubIntegration()

            if not gh.is_authenticated():
                return {
                    "task": "task5_auto_fix_code",
                    "status": "‚ùå FAILED",
                    "error": "GitHub not authenticated",
                }

            # –ï—Å–ª–∏ issue –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—â–µ–º –≤ –ª–æ–≥–∞—Ö
            if not issue_description:
                logs = self._read_journalctl_logs(since="1 hour ago")
                analysis = self._analyze_logs(logs)

                if analysis["error_count"] == 0:
                    return {
                        "task": "task5_auto_fix_code",
                        "status": "‚úÖ SKIP",
                        "reason": "No errors found in logs",
                    }

                # –ë–µ—Ä—ë–º —Å–∞–º—É—é —á–∞—Å—Ç—É—é –æ—à–∏–±–∫—É
                issue_description = f"Fix error: {analysis['top_errors'][0]}"

            # AI –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            prompt = f"""
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:

–ü—Ä–æ–±–ª–µ–º–∞: {issue_description}

–í–µ—Ä–Ω–∏ JSON:
{{
    "file_path": "–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å",
    "fixed_content": "–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ —Ü–µ–ª–∏–∫–æ–º",
    "explanation": "—á—Ç–æ –∏–º–µ–Ω–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ"
}}
"""

            print(f"üí≠ –°–ø—Ä–∞—à–∏–≤–∞—é AI –∫–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å: {issue_description[:80]}...")
            ai_response = agent.think(prompt, max_iterations=1)

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç AI
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                import re

                json_match = re.search(r"\{.*\}", ai_response, re.DOTALL)
                if not json_match:
                    raise ValueError("No JSON in AI response")

                fix_data = json.loads(json_match.group())
                file_path = fix_data["file_path"]
                fixed_content = fix_data["fixed_content"]
                explanation = fix_data["explanation"]

            except Exception as e:
                return {
                    "task": "task5_auto_fix_code",
                    "status": "‚ùå FAILED",
                    "error": f"Failed to parse AI response: {e}",
                }

            # –°–æ–∑–¥–∞—ë–º –≤–µ—Ç–∫—É
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            branch_name = f"autofix/{timestamp}"

            print(f"üåø –°–æ–∑–¥–∞—é –≤–µ—Ç–∫—É: {branch_name}")
            branch_result = gh.create_branch(
                owner="AgeeKey",
                repo="Mirai",
                branch_name=branch_name,
                from_branch="main",
            )

            if "error" in branch_result:
                return {
                    "task": "task5_auto_fix_code",
                    "status": "‚ùå FAILED",
                    "error": f"Failed to create branch: {branch_result['error']}",
                }

            # –ö–æ–º–º–∏—Ç–∏–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            print(f"üíæ –ö–æ–º–º–∏—á—É –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ {file_path}")
            commit_result = gh.create_or_update_file(
                owner="AgeeKey",
                repo="Mirai",
                path=file_path,
                content=fixed_content,
                message=f"ü§ñ Auto-fix: {issue_description[:50]}",
                branch=branch_name,
            )

            if "error" in commit_result:
                return {
                    "task": "task5_auto_fix_code",
                    "status": "‚ùå FAILED",
                    "error": f"Failed to commit: {commit_result['error']}",
                }

            # –°–æ–∑–¥–∞—ë–º Pull Request
            pr_body = f"""
## ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

**–ü—Ä–æ–±–ª–µ–º–∞:**
{issue_description}

**–ß—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ:**
{explanation}

**–ò–∑–º–µ–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª:**
- `{file_path}`

---
*–°–æ–∑–¥–∞–Ω–æ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–º –∞–≥–µ–Ω—Ç–æ–º MIRAI*
"""

            print(f"üì¨ –°–æ–∑–¥–∞—é Pull Request...")
            pr_result = gh.create_pull_request(
                owner="AgeeKey",
                repo="Mirai",
                title=f"ü§ñ Auto-fix: {issue_description[:60]}",
                head=branch_name,
                base="main",
                body=pr_body,
            )

            if "error" in pr_result:
                return {
                    "task": "task5_auto_fix_code",
                    "status": "‚ö†Ô∏è PARTIAL",
                    "branch": branch_name,
                    "commit": commit_result.get("sha"),
                    "error": f"PR creation failed: {pr_result['error']}",
                }

            return {
                "task": "task5_auto_fix_code",
                "status": "‚úÖ SUCCESS",
                "pr_number": pr_result["number"],
                "pr_url": pr_result["url"],
                "branch": branch_name,
                "file_fixed": file_path,
            }

        except Exception as e:
            return {
                "task": "task5_auto_fix_code",
                "status": "‚ùå FAILED",
                "error": str(e),
            }


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    executor = RealTaskExecutor()

    print("üöÄ –ó–∞–ø—É—Å–∫–∞—é –≤—Å–µ –†–ï–ê–õ–¨–ù–´–ï –∑–∞–¥–∞—á–∏ MIRAI\n")

    # –ó–∞–¥–∞—á–∞ 1: –ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤
    result1 = executor.task1_analyze_logs_and_report()
    print(f"\n1Ô∏è‚É£ {result1['task']}: {result1['status']}")

    # –ó–∞–¥–∞—á–∞ 2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ CI/CD (–¥–ª—è –ø—Ä–∏–º–µ—Ä–∞)
    mock_health = {
        "status": "UNHEALTHY",
        "grade": "D (50%)",
        "success_rate": "50%",
        "report": "2/4 workflows failed",
    }
    result2 = executor.task2_monitor_cicd_and_create_issue(mock_health)
    print(f"\n2Ô∏è‚É£ {result2['task']}: {result2['status']}")

    # –ó–∞–¥–∞—á–∞ 3: –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
    result3 = executor.task3_build_knowledge_base()
    print(f"\n3Ô∏è‚É£ {result3['task']}: {result3['status']}")

    # –ó–∞–¥–∞—á–∞ 4: Dashboard
    result4 = executor.task4_update_metrics_dashboard()
    print(f"\n4Ô∏è‚É£ {result4['task']}: {result4['status']}")

    print("\n" + "=" * 60)
    print("‚úÖ –í–°–ï 4 –ó–ê–î–ê–ß–ò –í–´–ü–û–õ–ù–ï–ù–´!")
    print("=" * 60)

    summary = {"task1": result1, "task2": result2, "task3": result3, "task4": result4}

    print(json.dumps(summary, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
